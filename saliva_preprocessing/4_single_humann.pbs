#!/bin/bash
# The interpreter used to execute the script

#“#SBATCH” directives that convey submission options:

#SBATCH --job-name=saliva_single_humann
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --nodes=1
#SBATCH --cpus-per-task=4
#SBATCH --mem=40g
#SBATCH --time=20:00:00
#SBATCH --account=bfoxman0
#SBATCH --partition=standard
#SBATCH --output=logs/saliva_single_humann.log

#module load
source /home/wangmk/.bashrc
micromamba activate biobakery

#set variables 
threads=4
chocophlan=/nfs/turbo/sph-bfoxman/reference_data/humann_db_v31/chocophlan/
uniref=/nfs/turbo/sph-bfoxman/reference_data/humann_db_v31/uniref/

prescreen=0.0001

#set input and output directory CHANGE ME 
#code should be where the max_table.R file lives
#in is the directory where the results from metaphlan are
in=concat_reads
taxa=metaphlan/merged_taxonomic_table_species_concise.tsv
out=humann
all_samples=($(ls -1Sr ${in}/*_cat.fq.gz))
one_sample=${all_samples[4]}


#run humann on one of your samples while providing the maximum taxonomic profile to create the custom indexed 
humann -i ${one_sample} -o ${out} --nucleotide-database ${chocophlan}  \
    --protein-database ${uniref} \
    -v --threads ${threads} \
    --taxonomic-profile ${taxa} \
    --prescreen-threshold ${prescreen}
